---
title: "RProject"
author: "Sebastian Karkos"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    keep_md: true
runtime: shiny
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tibble.width = Inf) # displays all columns.
options(max.print=999999)
output_dir <- "../output"
library(dplyr)
library(DT)
library(corrplot)
library(ggplot2)
library(caret)
library(RANN)
library(readxl)
library(C50)
library(shiny)
library(rmarkdown)
```

## Kod wyliczający wykorzystane biblioteki.
```{r librariesCOunt}
usedPackages <- as.data.frame(installed.packages()[,c(1,3:4)])
nrow(usedPackages)
```

## Kod zapewniający powtarzalność wyników przy każdym uruchomieniu raportu na tych samych danych.

```{r }
set.seed(100)
```


## Kod pozwalający wczytać dane z pliku.
```{r cache=TRUE}
myData <- read.csv(file="/Users/Lenovo/Desktop/R PROJEKT/all_summary/all_summary.csv", header = TRUE, sep = ";", nrows=10000)
nrow(myData)
```

## Kod usuwający z danych wiersze posiadające wartość zmiennej res_name równą..

```{r deleteRes_NameRows}
newData <- subset(myData, !(res_name %in% c('UNK','UNX','UNL','DUM','N','BLOB','ALA','ARG','ASN','ASP','CYS','GLN','GLU','GLY','HIS','ILE','LEU','LYS','MET','MSE','PHE','PRO','SEC','SER','THR','TRP','TYR','VAL','DA','DG','DT','DC','DU','A','G','T','C','U','HOH','H20','WAT')))
nrow(newData)
```

## Kod przetwarzający brakujące dane.
```{r}
#newData <- na.omit(newData)
```

## Sekcję podsumowującą rozmiar zbioru i podstawowe statystyki.
```{r dataStatistics}
summary(newData)
```

## Kod ograniczający liczbę klas (res_name) do 50 najpopularniejszych wartości.
## Określenie ile przykładów ma każda z klas (res_name).
```{r}
firstFifty <- names(sort(table(newData$res_name), decreasing = TRUE))
firstFifty[(1:50)]
firstFiftyWithValues <- sort(table(newData$res_name), decreasing = TRUE)
firstFiftyWithValues[1:50]

```

## Sekcję sprawdzającą korelacje między zmiennymi; sekcja ta powinna zawierać jakąś formę graficznej prezentacji korelacji.
```{r correlation}
#variableCorrelation <- newData[,2:length(newData)]
#round(cor(variableCorrelation),2)
numericCols <- dplyr::select_if(newData, is.numeric)
variableCorrelation <- numericCols[,2:length(numericCols)]
corDF <- as.data.frame(as.table(cor(variableCorrelation)))
corDF <- subset(corDF, Freq >= 0.99)
corDF <- subset(corDF, Var1 != Var2)
corDF <- corDF[!duplicated(t(apply(corDF, 1, sort))),]
#plot(newData$part_01_mean, newData$part_00_mean)
corDF
for(row in 1:nrow(corDF))
{
  x <- as.vector(corDF$Var1[[row]])
  y <- as.vector(corDF$Var2[[row]])
  plot(newData[,x], newData[,y], xlab=x, ylab=y)
}
```

## Wykresy rozkładów liczby atomów (local_res_atom_non_h_count) i elektronów (local_res_atom_non_h_electron_sum).
```{r }
qplot(res_id, local_res_atom_non_h_count, data = newData)
qplot(res_id, local_res_atom_non_h_electron_sum, data = newData)
 
```

## Tabelę pokazującą 10 klas z największą niezgodnością liczby atomów (local_res_atom_non_h_count vs dict_atom_non_h_count) i tabelę pokazującą 10 klas z największą niezgodnością liczby elektronów (local_res_atom_non_h_electron_sum vs dict_atom_non_h_electron_sum;)
```{r }
 
atomsDiffs <- select(newData, res_id, res_name, local_res_atom_non_h_count , dict_atom_non_h_count)
atomsDiffs <- mutate(atomsDiffs,diff=local_res_atom_non_h_count - dict_atom_non_h_count)
atomsDiffs <- atomsDiffs[order(atomsDiffs$diff, decreasing=FALSE), ]
 
prettyTable <- function(table_df, round_columns=numeric(), round_digits=2) {
    DT::datatable(table_df, style="bootstrap", filter = "top", rownames = FALSE, extensions = "Buttons", options = list(dom = 'Bfrtip', buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))) %>%
    formatRound(round_columns, round_digits)
}
 
prettyTable(head(atomsDiffs, 10))
 
electronDiffs <- select(newData, res_id, res_name, local_res_atom_non_h_electron_sum, dict_atom_non_h_electron_sum)
electronDiffs <- mutate(electronDiffs,diff=local_res_atom_non_h_electron_sum - dict_atom_non_h_electron_sum)
electronDiffs <- electronDiffs[order(electronDiffs$diff, decreasing=FALSE), ]
 
prettyTable(head(electronDiffs, 10))
 
```

## 12. Sekcja pokazujÄ…ca rozkĹ‚ad wartoĹ›ci wszystkich kolumn zaczynajÄ…cych siÄ™ od part_01 z zaznaczeniem (graficznym i liczbowym) Ĺ›redniej wartoĹ›ci.
```{r}
strangeVar <-  dplyr::select(newData, res_id, starts_with("part_01"))
selectInput("column", label = "Kolumna:",
            choices = colnames(strangeVar)[2:length(colnames(strangeVar))], selected = "part_01_shape_sqrt_E1")
```
```{r}
renderPlot({
  qplot(strangeVar[,1], strangeVar[,input$column], data = strangeVar, ylab=  input$column, xlab =colnames(strangeVar)[1] ) + stat_summary(fun.y=mean, geom="point", group="res_id", color="red", fill="red")
})
renderPlot({
  helperMean <- mean(strangeVar[,input$column], na.rm=T)
  ggplot(strangeVar, aes(strangeVar[,input$column], xlab=input$column, alpha=0.5)) + geom_density() +   geom_vline(aes(xintercept=helperMean), color="red", linetype="dashed", size=1, show_guide = TRUE) +  geom_text(aes(x=mean(strangeVar[,input$column], na.rm=T), label=round(helperMean,2), y=0), colour="blue", angle=0, text=element_text(size=12))
})
```


##14 Sekcję sprawdzającą czy na podstawie wartości innych kolumn można przewidzieć liczbę elektronów i atomów oraz z jaką dokładnością można dokonać takiej predykcji; trafność regresji powinna zostać oszacowana na podstawie miar R^2 i RMSE;
```{r}
numericCols <- numericCols %>% select(-one_of(c(
"weight_col",
"title",
"pbd_code",
"res_name",
"res_id",
"chain_id",
"local_BAa",
"local_NPa",
"local_Ra",
"local_RGa",
"local_SRGa",
"local_CCSa",
"local_CCPa",
"local_ZOa",
"local_ZDa",
"local_ZD_minus_a",
"local_ZD_plus_a",
"local_res_atom_count",
"local_res_atom_non_h_count",
"local_res_atom_non_h_occupancy_sum", 
#"local_res_atom_non_h_electron_sum", 
"local_res_atom_non_h_electron_occupancy_sum", "local_res_atom_C_count", 
"local_res_atom_N_count", 
"local_res_atom_O_count", 
"local_res_atom_S_count",
"dict_atom_non_h_count",
"dict_atom_non_h_electron_sum",
"dict_atom_C_count",
"dict_atom_N_count", 
"dict_atom_O_count", 
"dict_atom_S_count",
"fo_col",
"fc_col",
"weight_col",
"grid_space",
"solvent_radius",
"solvent_opening_radius",
"part_step_FoFc_std_min",
"part_step_FoFc_std_max",
"part_step_FoFc_std_step"
)))

numericCols <- as.data.frame(numericCols)
class(numericCols)
set.seed(100)
inTrain <- createDataPartition(y = numericCols$local_electrons, 
                               p = 0.8, list = FALSE)
training <- numericCols[inTrain,]
testing <- numericCols[-inTrain,]
colNo = which( colnames(training)=="local_res_atom_non_h_electron_sum" )
preProcValues <- preProcess(training, method = c("knnImpute","center","scale"))
set.seed(100)
train_processed <- predict(preProcValues, training)
set.seed(100)
my_lm = train(train_processed[,-colNo], train_processed[,colNo],
               method = "lm",
               preProc = c("center", "scale")
              )
my_lm
  
p <- predict(my_lm, testing)
summary(p)
  
Rsquared <- summary(my_lm)$r.squared
print(Rsquared)
#p
```


```{r }
memory.limit()
memory.limit(size = 56000)
```

## Sekcję próbującą stworzyć klasyfikator przewidujący wartość atrybutu res_name (w tej sekcji należy wykorzystać wiedzę z pozostałych punktów oraz wykonać dodatkowe czynności, które mogą poprawić trafność klasyfikacji); trafność klasyfikacji powinna zostać oszacowana na danych inne niż uczące za pomocą mechanizmu (stratyfikowanej!) oceny krzyżowej lub (stratyfikowanego!) zbioru testowego.
```{r cache=TRUE}
gc()
newData <- subset(myData, !(res_name %in% firstFifty[(1:50)]))
nrow(newData)
#newData <- dplyr::select(myData,everything()) %>% filter(res_name == 'SO4' | res_name == 'GOL' | res_name == 'EDO' | res_name == 'NAG')
newData <- newData[!is.na(newData$res_name),]
nrow(newData)
newData <- as.data.frame(newData)
newData <- droplevels(newData)
set.seed(100)
inTrain <- createDataPartition(y = newData$res_name,
                               p = 0.8, list = FALSE)
 training <- newData[inTrain,]
 testing <- newData[-inTrain,]
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
set.seed(100)
#preProcValues <- preProcess(training, method = c("knnImpute","center","scale"))
#train_processed <- predict(preProcValues, training)
fit.lda <- train(res_name ~ res_volume_coverage+local_max_over_std+resolution+local_skewness+local_std+local_mean+local_volume+local_electrons+local_max+res_volume_coverage_second, data=training, method="lda", metric=metric, trControl=control,na.action = na.pass)
# CART
set.seed(100)
fit.cart <- train(res_name ~ res_volume_coverage+local_max_over_std+resolution+local_skewness+local_std+local_mean+local_volume+local_electrons+local_max+res_volume_coverage_second, data=training, method="rpart", metric=metric, trControl=control,na.action = na.pass)
# kNN
#set.seed(100)
#fit.knn <- train(res_name~res_volume_coverage+local_max_over_std+resolution+local_skewness+local_std+local_mean+local_volume+local_electrons+local_max+res_volume_coverage_second, data=training, method="knn", metric=metric, trControl=control,na.action = na.pass)
#set.seed(100)
#fit.svm <- train(res_name~res_volume_coverage+local_max_over_std+resolution+local_skewness+local_std+local_mean+local_volume+local_electrons+local_max+res_volume_coverage_second, data=training, method="svmRadial", metric=metric, trControl=control,na.action = na.pass)
#set.seed(100)
#fit.rf <- train(res_name~res_volume_coverage+local_max_over_std+resolution+local_skewness+local_std+local_mean+local_volume+local_electrons+local_max+res_volume_coverage_second, data=training, method="rf", metric=metric, trControl=control,na.action = na.pass)
 
results <- resamples(list(lda=fit.lda, cart=fit.cart))
summary(results)
 
predictions <- predict(fit.lda, testing)
confusionMatrix(predictions, testing$res_name)
```



